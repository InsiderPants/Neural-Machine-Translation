{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.preprocessing import *\n",
    "from utils.model import *\n",
    "from utils.config import *\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PATH_ENG = 'data/small_vocab_en'\n",
    "PATH_FR = 'data/small_vocab_fr'\n",
    "PATH_GLOVE = 'data/glove.6B.100d.txt'\n",
    "MODEL_SAVE_PATH = 'weights/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading English Lines\n",
      "Reading French Lines\n"
     ]
    }
   ],
   "source": [
    "# Reading dataset\n",
    "english = read_english(PATH_ENG)\n",
    "french, french_inputs = read_french(PATH_FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding maximum length of input snetence\n",
    "max_len_input = max(len(s) for s in english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing English Texts\n",
      "Found 199 unique english tokens\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing English\n",
    "input_sequence, word2idx_english = tokenize_english(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing French Texts\n",
      "Found 353 unique french tokens\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing French\n",
    "target_sequence, target_sequence_inputs, word2idx_french = tokenize_french(french, french_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_output = len(word2idx_french) + 1\n",
    "max_len_target = max(len(s) for s in target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding..\n"
     ]
    }
   ],
   "source": [
    "# Padding all inputs for encoder and decoders\n",
    "encoder_inputs, decoder_inputs, decoder_targets = padding(input_sequence,\n",
    "                                                          target_sequence, \n",
    "                                                          target_sequence_inputs, \n",
    "                                                          max_len_input, \n",
    "                                                          max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe word embedding\n",
      "Found 400000 word vectors\n",
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Loading GloVe Word Embedding\n",
    "word2vec, embedding_matrix = glove_embedding(word2idx_english, PATH_GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word2idx_english) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object of model class\n",
    "x = model(num_words, embedding_matrix, max_len_input, max_len_target, num_words_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "train_model = x.Seq2SeqModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading weights\n",
    "train_model.load_weights(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "train_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_eng = {v:k for k, v in word2idx_english.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_french.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction model\n",
    "prediction_model = x.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter String i am driving\n",
      "-\n",
      "Input sentence: i am driving\n",
      "Predicted translation: je , aimã© , mais mon .\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    final_input_seq = []\n",
    "    n=199\n",
    "    input_seq = input(\"Enter String \")\n",
    "    for word in input_seq.split():\n",
    "        if word in word2idx_english:\n",
    "            final_input_seq.append(word2idx_english[word])\n",
    "        else:\n",
    "            n = n+1\n",
    "            final_input_seq.append(n)\n",
    "    final_input_seq = pad_sequences([final_input_seq], maxlen=max_len_input)\n",
    "    translation = x.decode_sequence(final_input_seq, word2idx_french, prediction_model, idx2word_trans)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_seq)\n",
    "    print('Predicted translation:', translation)\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
