{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.preprocessing import *\n",
    "from utils.model import *\n",
    "from utils.config import *\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PATH_ENG = 'data/small_vocab_en'\n",
    "PATH_FR = 'data/small_vocab_fr'\n",
    "PATH_GLOVE = 'data/glove.6B.100d.txt'\n",
    "MODEL_SAVE_PATH = 'weights/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading English Lines\n",
      "Reading French Lines\n"
     ]
    }
   ],
   "source": [
    "# Reading dataset\n",
    "english = read_english(PATH_ENG)\n",
    "french, french_inputs = read_french(PATH_FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding maximum length of input snetence\n",
    "max_len_input = max(len(s) for s in english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing English Texts\n",
      "Found 199 unique english tokens\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing English\n",
    "input_sequence, word2idx_english = tokenize_english(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing French Texts\n",
      "Found 353 unique french tokens\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing French\n",
    "target_sequence, target_sequence_inputs, word2idx_french = tokenize_french(french, french_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_output = len(word2idx_french) + 1\n",
    "max_len_target = max(len(s) for s in target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding..\n"
     ]
    }
   ],
   "source": [
    "# Padding all inputs for encoder and decoders\n",
    "encoder_inputs, decoder_inputs, decoder_targets = padding(input_sequence,\n",
    "                                                          target_sequence, \n",
    "                                                          target_sequence_inputs, \n",
    "                                                          max_len_input, \n",
    "                                                          max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe word embedding\n",
      "Found 400000 word vectors\n",
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Loading GloVe Word Embedding\n",
    "word2vec, embedding_matrix = glove_embedding(word2idx_english, PATH_GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word2idx_english) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object of model class\n",
    "x = model(num_words, embedding_matrix, max_len_input, max_len_target, num_words_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "train_model = x.Seq2SeqModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading weights\n",
    "train_model.load_weights(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "train_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_eng = {v:k for k, v in word2idx_english.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_french.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction model\n",
    "prediction_model = x.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: india is sometimes nice during summer , and it is quiet in february .\n",
      "Predicted translation: l' inde est parfois agrã©able pendant l' ã©tã© , et il est calme en fã©vrier .\n",
      "Actual translation: l' inde est parfois agrÃ©able pendant l' Ã©tÃ© , et il est calme en fÃ©vrier . <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: the united states is never warm during december , and it is sometimes freezing in september .\n",
      "Predicted translation: les ã©tats-unis est jamais chaud en dã©cembre , et il est parfois le gel en septembre .\n",
      "Actual translation: les Ã©tats-unis est jamais chaud en dÃ©cembre , et il est parfois le gel en septembre . <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: this dog is your least favorite animal .\n",
      "Predicted translation: ce chien est votre animal prã©fã©rã© moins .\n",
      "Actual translation: ce chien est votre animal prÃ©fÃ©rÃ© moins . <eos>\n",
      "Continue? [Y/n]y\n",
      "-\n",
      "Input sentence: the mango is my least favorite fruit , but the grapefruit is her least favorite .\n",
      "Predicted translation: la mangue est moins mon fruit prã©fã©rã© , mais le pamplemousse est son moins prã©fã©rã© .\n",
      "Actual translation: la mangue est mon fruit prÃ©fÃ©rÃ© moins , mais le pamplemousse est son moins prÃ©fÃ©rÃ© . <eos>\n",
      "Continue? [Y/n]\n",
      "-\n",
      "Input sentence: we like limes , oranges , and strawberries.\n",
      "Predicted translation: nous aimons citrons verts , les oranges et les fraises .\n",
      "Actual translation: nous aimons citrons verts , les oranges et les fraises . <eos>\n",
      "Continue? [Y/n]\n",
      "-\n",
      "Input sentence: india is quiet during april , but it is never hot in autumn .\n",
      "Predicted translation: l' inde est calme en avril , mais il est jamais chaud ã  l' automne .\n",
      "Actual translation: l' inde est calme en avril , mais il est jamais chaud Ã  l' automne . <eos>\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    #Do some test translations\n",
    "    i = np.random.choice(len(english))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    translation = x.decode_sequence(input_seq, word2idx_french, prediction_model, idx2word_trans)\n",
    "    print('-')\n",
    "    print('Input sentence:', english[i])\n",
    "    print('Predicted translation:', translation)\n",
    "    print('Actual translation:', french[i])\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
